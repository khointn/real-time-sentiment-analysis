{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport random\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T12:37:16.873342Z","iopub.execute_input":"2022-05-02T12:37:16.874114Z","iopub.status.idle":"2022-05-02T12:37:23.976924Z","shell.execute_reply.started":"2022-05-02T12:37:16.874018Z","shell.execute_reply":"2022-05-02T12:37:23.975839Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Image Data Generator & Preprocessing","metadata":{}},{"cell_type":"code","source":"#### Use Image Data Generator to call data to prevent OOM\n\nIMG_SIZE = 48\nbatch_size = 100\n\ntrain_datagen = ImageDataGenerator(\n        shear_range=0.2, ### Augmentation: the IDG will randomly apply augmentation on every image, and use that augmented \n        zoom_range=0.2,   ### data to train instead of using the original data.\n        horizontal_flip=True,\n        validation_split=0.1, ### split for validation. Train : validation = 9:1\n        preprocessing_function=tf.keras.applications.imagenet_utils.preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n        \"../input/fer2013/train\",\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=batch_size,\n        class_mode='binary',\n        subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n        \"../input/fer2013/train\",\n        target_size=(IMG_SIZE, IMG_SIZE), \n        batch_size=batch_size,\n        class_mode='binary',\n        subset='validation')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T12:37:49.587077Z","iopub.execute_input":"2022-05-02T12:37:49.587351Z","iopub.status.idle":"2022-05-02T12:38:05.408220Z","shell.execute_reply.started":"2022-05-02T12:37:49.587320Z","shell.execute_reply":"2022-05-02T12:38:05.407130Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 25841 images belonging to 7 classes.\nFound 2868 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"### Create test set.\n\ntest_datagen = ImageDataGenerator(\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        preprocessing_function=tf.keras.applications.imagenet_utils.preprocess_input)\n\ntest_generator = test_datagen.flow_from_directory(\n        \"../input/fer2013/test\",\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=batch_size,\n        class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T12:38:05.411142Z","iopub.execute_input":"2022-05-02T12:38:05.411503Z","iopub.status.idle":"2022-05-02T12:38:08.455207Z","shell.execute_reply.started":"2022-05-02T12:38:05.411457Z","shell.execute_reply":"2022-05-02T12:38:08.454213Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"### check distribution:\nfor sentiment in list(train_generator.class_indices.keys()):\n    print(sentiment, sum(sentiment in s for s in train_generator.filenames))\n    \n### We can see that the data is skewed, since 'happy' sentiment occurs many time and 'disgust' occurs very few.\n### To prevent this, we can use resampling. However, I will not use resampling for this project","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T12:47:21.813186Z","iopub.execute_input":"2022-05-02T12:47:21.813708Z","iopub.status.idle":"2022-05-02T12:47:21.883486Z","shell.execute_reply.started":"2022-05-02T12:47:21.813645Z","shell.execute_reply":"2022-05-02T12:47:21.882423Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"angry 3596\ndisgust 393\nfear 3688\nhappy 6494\nneutral 4469\nsad 4347\nsurprise 2854\n","output_type":"stream"}]},{"cell_type":"code","source":"#### Load pretrained model (if have):\n#### This is my pretrained model with accuracy over test set is 0.6095\nmodel = tf.keras.models.load_model(\"../input/pretrained-model/cnn_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T12:49:17.980293Z","iopub.execute_input":"2022-05-02T12:49:17.980599Z","iopub.status.idle":"2022-05-02T12:49:18.327916Z","shell.execute_reply.started":"2022-05-02T12:49:17.980567Z","shell.execute_reply":"2022-05-02T12:49:18.326862Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Simple CNN","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32,(3,3), padding=\"same\", input_shape=(224, 224, 3)))\n#model.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(32,(3,3), padding=\"same\"))\n#model.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64,(3,3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(64,(3,3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128,(3,3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(128,(3,3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#model.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\n#model.add(BatchNormalization())\nmodel.add(Dense(64))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\n#model.add(BatchNormalization())\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dense(7))\n#model.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Activation(\"softmax\"))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T12:48:53.903764Z","iopub.execute_input":"2022-05-02T12:48:53.904104Z","iopub.status.idle":"2022-05-02T12:48:54.099923Z","shell.execute_reply.started":"2022-05-02T12:48:53.904072Z","shell.execute_reply":"2022-05-02T12:48:54.098914Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 224, 224, 32)      896       \n_________________________________________________________________\nactivation (Activation)      (None, 224, 224, 32)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 224, 224, 32)      9248      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 224, 224, 32)      0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 112, 112, 64)      18496     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 112, 112, 64)      36928     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 112, 112, 64)      0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 56, 56, 128)       73856     \n_________________________________________________________________\nactivation_4 (Activation)    (None, 56, 56, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 56, 56, 128)       147584    \n_________________________________________________________________\nactivation_5 (Activation)    (None, 56, 56, 128)       0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n_________________________________________________________________\ndense (Dense)                (None, 28, 28, 128)       16512     \n_________________________________________________________________\nactivation_6 (Activation)    (None, 28, 28, 128)       0         \n_________________________________________________________________\ndropout (Dropout)            (None, 28, 28, 128)       0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 28, 28, 64)        8256      \n_________________________________________________________________\nactivation_7 (Activation)    (None, 28, 28, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 28, 28, 64)        0         \n_________________________________________________________________\nglobal_max_pooling2d (Global (None, 64)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 455       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 7)                 0         \n=================================================================\nTotal params: 312,231\nTrainable params: 312,231\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#aug=ImageDataGenerator(rotation_range=0.18, zoom_range=0.15, width_shift_range=0.2,height_shift_range=0.2, horizontal_flip=True)\n#opt= SGD(learning_rate=0.01,momentum=0.9)\n\ncheckpoint = ModelCheckpoint('best-weights.h5', monitor='val_loss', save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T12:48:57.213706Z","iopub.execute_input":"2022-05-02T12:48:57.214025Z","iopub.status.idle":"2022-05-02T12:48:57.219423Z","shell.execute_reply.started":"2022-05-02T12:48:57.213993Z","shell.execute_reply":"2022-05-02T12:48:57.218361Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"'''\nBUFFER_SIZE = 2000\n\ndef make_ds(features, labels):\n  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n  ds = ds.shuffle(BUFFER_SIZE).repeat()\n  return ds\n\npos_ds = make_ds(train_generator, train_generator.classes)\n\nresampled_ds = pos_ds.batch(batch_size).prefetch(2)\n\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T12:48:59.363417Z","iopub.execute_input":"2022-05-02T12:48:59.363703Z","iopub.status.idle":"2022-05-02T12:48:59.370963Z","shell.execute_reply.started":"2022-05-02T12:48:59.363672Z","shell.execute_reply":"2022-05-02T12:48:59.369911Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'\\nBUFFER_SIZE = 2000\\n\\ndef make_ds(features, labels):\\n  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\\n  ds = ds.shuffle(BUFFER_SIZE).repeat()\\n  return ds\\n\\npos_ds = make_ds(train_generator, train_generator.classes)\\n\\nresampled_ds = pos_ds.batch(batch_size).prefetch(2)\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"### Training using pretrained model, or we can also use the new model.\n### I have trained before with 100 epochs, now I run 15 epochs just for showing the result\n\nbatch_size = 100\nopt= SGD(learning_rate=0.00005, momentum =0.9)\nmodel.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = ['accuracy'])\nmodel.fit(train_generator, epochs = 15, batch_size = batch_size,validation_data = validation_generator, \n          steps_per_epoch =train_generator.samples//batch_size,callbacks=[checkpoint])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T12:49:29.039070Z","iopub.execute_input":"2022-05-02T12:49:29.039363Z","iopub.status.idle":"2022-05-02T13:09:29.626914Z","shell.execute_reply.started":"2022-05-02T12:49:29.039326Z","shell.execute_reply":"2022-05-02T13:09:29.625864Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-05-02 12:49:29.958411: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"2022-05-02 12:49:32.661329: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"258/258 [==============================] - 203s 754ms/step - loss: 0.9621 - accuracy: 0.6398 - val_loss: 1.0532 - val_accuracy: 0.6067\nEpoch 2/15\n258/258 [==============================] - 52s 202ms/step - loss: 0.9649 - accuracy: 0.6360 - val_loss: 1.0430 - val_accuracy: 0.6074\nEpoch 3/15\n258/258 [==============================] - 53s 205ms/step - loss: 0.9628 - accuracy: 0.6383 - val_loss: 1.0434 - val_accuracy: 0.6056\nEpoch 4/15\n258/258 [==============================] - 52s 203ms/step - loss: 0.9581 - accuracy: 0.6411 - val_loss: 1.0359 - val_accuracy: 0.6091\nEpoch 5/15\n258/258 [==============================] - 51s 197ms/step - loss: 0.9583 - accuracy: 0.6401 - val_loss: 1.0494 - val_accuracy: 0.6032\nEpoch 6/15\n258/258 [==============================] - 52s 201ms/step - loss: 0.9606 - accuracy: 0.6392 - val_loss: 1.0496 - val_accuracy: 0.6046\nEpoch 7/15\n258/258 [==============================] - 51s 199ms/step - loss: 0.9567 - accuracy: 0.6410 - val_loss: 1.0574 - val_accuracy: 0.6004\nEpoch 8/15\n258/258 [==============================] - 52s 201ms/step - loss: 0.9602 - accuracy: 0.6422 - val_loss: 1.0483 - val_accuracy: 0.6032\nEpoch 9/15\n258/258 [==============================] - 52s 201ms/step - loss: 0.9580 - accuracy: 0.6411 - val_loss: 1.0490 - val_accuracy: 0.6032\nEpoch 10/15\n258/258 [==============================] - 53s 204ms/step - loss: 0.9579 - accuracy: 0.6398 - val_loss: 1.0505 - val_accuracy: 0.6025\nEpoch 11/15\n258/258 [==============================] - 51s 198ms/step - loss: 0.9595 - accuracy: 0.6416 - val_loss: 1.0400 - val_accuracy: 0.6098\nEpoch 12/15\n258/258 [==============================] - 52s 201ms/step - loss: 0.9562 - accuracy: 0.6419 - val_loss: 1.0439 - val_accuracy: 0.6036\nEpoch 13/15\n258/258 [==============================] - 51s 199ms/step - loss: 0.9563 - accuracy: 0.6397 - val_loss: 1.0537 - val_accuracy: 0.6102\nEpoch 14/15\n258/258 [==============================] - 53s 205ms/step - loss: 0.9516 - accuracy: 0.6417 - val_loss: 1.0447 - val_accuracy: 0.6032\nEpoch 15/15\n258/258 [==============================] - 51s 199ms/step - loss: 0.9580 - accuracy: 0.6401 - val_loss: 1.0375 - val_accuracy: 0.6095\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f6fb7d1b0d0>"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T12:18:25.633252Z","iopub.execute_input":"2022-05-02T12:18:25.633524Z","iopub.status.idle":"2022-05-02T12:19:48.253395Z","shell.execute_reply.started":"2022-05-02T12:18:25.633492Z","shell.execute_reply":"2022-05-02T12:19:48.252718Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"72/72 [==============================] - 46s 644ms/step - loss: 1.0594 - accuracy: 0.6095\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[1.0593725442886353, 0.6095012426376343]"},"metadata":{}}]},{"cell_type":"code","source":"### model predict image:\nimg_array = cv2.imread(\"../input/fer2013/train/disgust/Training_10598340.jpg\")\nimg_size = 224\nresized_array = cv2.resize(img_array, (img_size, img_size))\nresized_array = np.expand_dims(resized_array, axis = 0)\n\nnp.argmax(model.predict(resized_array))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:43:11.811527Z","iopub.execute_input":"2022-05-02T11:43:11.811816Z","iopub.status.idle":"2022-05-02T11:43:11.862865Z","shell.execute_reply.started":"2022-05-02T11:43:11.811776Z","shell.execute_reply":"2022-05-02T11:43:11.862211Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"model.save(\"cnn_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T13:12:05.709709Z","iopub.execute_input":"2022-05-02T13:12:05.710075Z","iopub.status.idle":"2022-05-02T13:12:05.775000Z","shell.execute_reply.started":"2022-05-02T13:12:05.710043Z","shell.execute_reply":"2022-05-02T13:12:05.773694Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Deep Learning & Transfer Learning","metadata":{}},{"cell_type":"code","source":"### change last layers so that the final output will be 7 corresponds to 7 sentiments.\n\n### take input\nbase_input = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n### use pretrained ResNet\nmodel = tf.keras.applications.ResNet50(include_top=False, pooling=\"max\", weights=\"imagenet\")(base_input)\n\n### Add new layers\n\nfinal_output = layers.Dense(128)(model)\nfinal_output = layers.Activation('relu')(final_output)\nfinal_output = layers.BatchNormalization()(final_output)\nfinal_output = layers.Dense(64)(final_output)\nfinal_output = layers.Activation('relu')(final_output)\nfinal_output = layers.BatchNormalization()(final_output)\nfinal_output = layers.Dense(7, activation = 'softmax')(final_output)\nfinal_output","metadata":{"execution":{"iopub.status.busy":"2022-05-02T13:12:51.774490Z","iopub.execute_input":"2022-05-02T13:12:51.774871Z","iopub.status.idle":"2022-05-02T13:12:55.269996Z","shell.execute_reply.started":"2022-05-02T13:12:51.774836Z","shell.execute_reply":"2022-05-02T13:12:55.268831Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 1s 0us/step\n94781440/94765736 [==============================] - 1s 0us/step\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'dense_5')>"},"metadata":{}}]},{"cell_type":"code","source":"#### model summary\nnew_model = keras.Model(inputs = base_input, outputs = final_output)\nnew_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T13:12:59.455425Z","iopub.execute_input":"2022-05-02T13:12:59.455714Z","iopub.status.idle":"2022-05-02T13:12:59.490332Z","shell.execute_reply.started":"2022-05-02T13:12:59.455667Z","shell.execute_reply":"2022-05-02T13:12:59.488735Z"},"scrolled":true,"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 48, 48, 3)]       0         \n_________________________________________________________________\nresnet50 (Functional)        (None, 2048)              23587712  \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               262272    \n_________________________________________________________________\nactivation_9 (Activation)    (None, 128)               0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 128)               512       \n_________________________________________________________________\ndense_4 (Dense)              (None, 64)                8256      \n_________________________________________________________________\nactivation_10 (Activation)   (None, 64)                0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 64)                256       \n_________________________________________________________________\ndense_5 (Dense)              (None, 7)                 455       \n=================================================================\nTotal params: 23,859,463\nTrainable params: 23,805,959\nNon-trainable params: 53,504\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"opt= SGD(learning_rate=0.0003, momentum =0.9)\n\nearly_stopping_monitor = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0,\n    patience=0,\n    verbose=0,\n    mode='auto',\n    baseline=None,\n    restore_best_weights=True\n)\n\ncheckpoint = ModelCheckpoint('best-weights.h5', monitor='val_loss', save_best_only=True)\n\nnew_model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T13:13:09.932245Z","iopub.execute_input":"2022-05-02T13:13:09.932550Z","iopub.status.idle":"2022-05-02T13:13:09.951464Z","shell.execute_reply.started":"2022-05-02T13:13:09.932519Z","shell.execute_reply":"2022-05-02T13:13:09.950251Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#callbacks=[early_stopping_monitor]\n### I have trained before with 100 epochs and got about 0.5700 accuracy, but I lost that h5 file. Now I rerun with 20 epochs just for showing.\nnew_model.fit(train_generator, validation_data=validation_generator, callbacks=[checkpoint], epochs=20,verbose=1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T13:13:44.728607Z","iopub.execute_input":"2022-05-02T13:13:44.728938Z","iopub.status.idle":"2022-05-02T13:34:13.704729Z","shell.execute_reply.started":"2022-05-02T13:13:44.728906Z","shell.execute_reply":"2022-05-02T13:34:13.703840Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/20\n259/259 [==============================] - 66s 228ms/step - loss: 2.1829 - accuracy: 0.2204 - val_loss: 1.9780 - val_accuracy: 0.3075\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20\n259/259 [==============================] - 57s 219ms/step - loss: 1.7612 - accuracy: 0.3502 - val_loss: 1.8081 - val_accuracy: 0.3563\nEpoch 3/20\n259/259 [==============================] - 57s 221ms/step - loss: 1.5806 - accuracy: 0.4191 - val_loss: 1.6108 - val_accuracy: 0.4202\nEpoch 4/20\n259/259 [==============================] - 58s 223ms/step - loss: 1.4724 - accuracy: 0.4515 - val_loss: 1.5219 - val_accuracy: 0.4355\nEpoch 5/20\n259/259 [==============================] - 58s 224ms/step - loss: 1.3928 - accuracy: 0.4847 - val_loss: 1.4703 - val_accuracy: 0.4606\nEpoch 6/20\n259/259 [==============================] - 57s 220ms/step - loss: 1.3371 - accuracy: 0.5008 - val_loss: 1.4270 - val_accuracy: 0.4742\nEpoch 7/20\n259/259 [==============================] - 57s 218ms/step - loss: 1.2916 - accuracy: 0.5210 - val_loss: 1.3780 - val_accuracy: 0.4826\nEpoch 8/20\n259/259 [==============================] - 57s 220ms/step - loss: 1.2455 - accuracy: 0.5340 - val_loss: 1.3487 - val_accuracy: 0.4934\nEpoch 9/20\n259/259 [==============================] - 57s 219ms/step - loss: 1.2073 - accuracy: 0.5509 - val_loss: 1.3246 - val_accuracy: 0.5007\nEpoch 10/20\n259/259 [==============================] - 56s 216ms/step - loss: 1.1749 - accuracy: 0.5641 - val_loss: 1.3240 - val_accuracy: 0.5059\nEpoch 11/20\n259/259 [==============================] - 57s 219ms/step - loss: 1.1425 - accuracy: 0.5782 - val_loss: 1.2955 - val_accuracy: 0.5220\nEpoch 12/20\n259/259 [==============================] - 58s 225ms/step - loss: 1.1159 - accuracy: 0.5859 - val_loss: 1.2837 - val_accuracy: 0.5146\nEpoch 13/20\n259/259 [==============================] - 59s 229ms/step - loss: 1.0833 - accuracy: 0.6001 - val_loss: 1.2715 - val_accuracy: 0.5293\nEpoch 14/20\n259/259 [==============================] - 61s 234ms/step - loss: 1.0566 - accuracy: 0.6078 - val_loss: 1.2542 - val_accuracy: 0.5300\nEpoch 15/20\n259/259 [==============================] - 62s 241ms/step - loss: 1.0273 - accuracy: 0.6211 - val_loss: 1.2575 - val_accuracy: 0.5317\nEpoch 16/20\n259/259 [==============================] - 61s 234ms/step - loss: 1.0010 - accuracy: 0.6334 - val_loss: 1.2694 - val_accuracy: 0.5397\nEpoch 17/20\n259/259 [==============================] - 64s 248ms/step - loss: 0.9793 - accuracy: 0.6404 - val_loss: 1.2487 - val_accuracy: 0.5408\nEpoch 18/20\n259/259 [==============================] - 65s 251ms/step - loss: 0.9584 - accuracy: 0.6483 - val_loss: 1.2452 - val_accuracy: 0.5446\nEpoch 19/20\n259/259 [==============================] - 59s 227ms/step - loss: 0.9294 - accuracy: 0.6607 - val_loss: 1.2245 - val_accuracy: 0.5408\nEpoch 20/20\n259/259 [==============================] - 62s 238ms/step - loss: 0.9103 - accuracy: 0.6687 - val_loss: 1.2303 - val_accuracy: 0.5575\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f6f5300e990>"},"metadata":{}}]},{"cell_type":"code","source":"new_model.save(\"transfer_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T13:36:12.469063Z","iopub.execute_input":"2022-05-02T13:36:12.469461Z","iopub.status.idle":"2022-05-02T13:36:13.324311Z","shell.execute_reply.started":"2022-05-02T13:36:12.469429Z","shell.execute_reply":"2022-05-02T13:36:13.323230Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"new_model = tf.keras.models.load_model(\"transfer_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-01T08:36:32.316016Z","iopub.execute_input":"2022-05-01T08:36:32.316483Z","iopub.status.idle":"2022-05-01T08:36:34.575902Z","shell.execute_reply.started":"2022-05-01T08:36:32.316438Z","shell.execute_reply":"2022-05-01T08:36:34.575151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 20 epochs got 0.5678 accuracy on test set.\nnew_model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T13:34:57.952989Z","iopub.execute_input":"2022-05-02T13:34:57.953300Z","iopub.status.idle":"2022-05-02T13:35:18.710690Z","shell.execute_reply.started":"2022-05-02T13:34:57.953268Z","shell.execute_reply":"2022-05-02T13:35:18.709706Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"72/72 [==============================] - 14s 200ms/step - loss: 1.1946 - accuracy: 0.5678\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[1.1946264505386353, 0.5678461790084839]"},"metadata":{}}]}]}